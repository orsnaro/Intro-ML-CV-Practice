{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # **Name:** _Omar Rashad Salem_\n",
    "> # **Course:** _CV - prof.Heba_\n",
    "> # **Assignemnt No.:** _4_\n",
    "\n",
    "> ## QUESTIONS\n",
    "\n",
    "##### _1)_ **What is a Convolutional Neural Network (CNN) and what makes it suitable for image-related tasks?**\n",
    "\n",
    "**ans:** \n",
    "- CNN  is type of neural networks that is used for processing  a higher dimensional type of data or cluster of data like images e.g.(rgb / gray scale) it posseses the ability to learn  patterns and hierarchical\n",
    " representations\n",
    "----\n",
    "\n",
    "##### _2)_ **Explain the concept of local connectivity in CNNs.**\n",
    "\n",
    "**ans:**  output of neuron in a X layer connects only to a small local region in the next layer that mostly share some similar context.  this effectively reduces `CNN` complexity and optimizes it!\n",
    "\n",
    "----\n",
    "##### _3)_ **What are the key parameters of a Convolutional Layer?**\n",
    "\n",
    "**ans:** \n",
    "- No. of filters `K`\n",
    "- Stride `S`\n",
    "- Filter size `F`\n",
    "- Zero padding `P`\n",
    "\n",
    "\n",
    "----\n",
    "##### _4)_ **Why is zero-padding used in Convolutional Layers, and what impact does it have on the spatial arrangement?**\n",
    "\n",
    "**ans:**\n",
    "- preserves the input dimensions / makes it managable\n",
    "- marks the edges of an images which could come very handy in image processing and computer vision\n",
    "\n",
    "----\n",
    "##### _5)_ **What is the purpose of pooling layer in ConvNet?**\n",
    "\n",
    "\n",
    "**ans:** \n",
    "- reduces the dimensions and parameters which helps boosting CNN over all performance and computing time\n",
    "- produces no extra parameters \n",
    "\n",
    "\n",
    "----\n",
    "##### _6)_ **SOLVE**\n",
    "given:\n",
    "\n",
    "\t\t- filter size = 2x2\n",
    " \t\t- stride = 2\n",
    "\t\t- i/p size = 28x28x64\n",
    "\t\t- it's a pooling layer\n",
    "\n",
    "* Find o/p Volume?\n",
    "\n",
    "**ans:** \n",
    "$$\n",
    "\tW = (w - f)/s + 1\n",
    "\t\\\\\n",
    "\tW = (16 - 2) / 2 + 1\n",
    "\t\\\\\n",
    "\t\\therefore W = 14\n",
    "\t\\\\\n",
    "\to/p-Volume = 14 * 14 * 64\n",
    "\t\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "----\n",
    "##### _7)_ **SOLVE**\n",
    "\n",
    "given:\n",
    "\n",
    "\t\t- filter size = 3x3\n",
    "\t\t- filters No. = 32\n",
    " \t\t- stride = 1\n",
    "\t\t- i/p size = 32x32x3\n",
    "\t\t- it's a Convolution layer\n",
    "\n",
    "* Find o/p Volume?\n",
    "\n",
    "**ans:** \n",
    "$$\n",
    "\tW = (w - f + 2p)/s + 1\n",
    "\t\\\\\n",
    "\tW = (32 - 3 + 2*0) / 1 + 1\n",
    "\t\\\\\n",
    "\t\\therefore W = 30\n",
    "\t\\\\\n",
    "\to/p-Volume = 30 * 30 * 32\n",
    "\t\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "----\n",
    "##### _8)_ **SOLVE**\n",
    "\n",
    "given:\n",
    "\n",
    "\t\t- filter size = 3x3\n",
    "\t\t- filters No. = 8\n",
    " \t\t\n",
    "* Find No. of parameters including biases?\n",
    "\n",
    "**ans:** \n",
    "$$\n",
    "\tNo.parameters = filter'size * depth * biases\n",
    "\t\\\\\n",
    "\t= 3 * 3 * 3 + 1 \n",
    "\t\\\\\n",
    "\to/p-Volume = 28 \n",
    "\t\\\\\n",
    "\t\\therefore No.parameters = 28*8 = 224\n",
    "$$\n",
    "\n",
    "\n",
    "----\n",
    "##### _9)_ **SOLVE**\n",
    "\n",
    "given:\n",
    "\n",
    "\t\t- i/p volume = 256*256*3\n",
    "\t\t- layer neurons no. = 100\n",
    " \t\t\n",
    "* Find No. weights and biases needed?\n",
    "\n",
    "**ans:** \n",
    "$$\n",
    "\tweights = 256*256*3*100 \n",
    "\t\\\\\n",
    "\tweights = 19660800\n",
    "\t\\\\\n",
    "\tbiases = 1*100 = 100\n",
    "$$\n",
    "\n",
    "\n",
    "----\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Programming Assignment _(challenge task!)_: \n",
    "> #### Image Classification using Convolutional Neural Networks (ConvNet)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # Code for accuracy FOCUSED CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\python311\\lib\\site-packages\\vboxapi-1.0-py3.11.egg is deprecated. pip 23.3 will enforce this behaviour change. A possible replacement is to use pip for package installation..\n",
      "DEPRECATION: textract 1.6.5 has a non-standard dependency specifier extract-msg<=0.29.*. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of textract or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imgaug in c:\\python311\\lib\\site-packages (0.4.0)\n",
      "Requirement already satisfied: six in c:\\python311\\lib\\site-packages (from imgaug) (1.16.0)\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\python311\\lib\\site-packages (from imgaug) (1.23.5)\n",
      "Requirement already satisfied: scipy in c:\\python311\\lib\\site-packages (from imgaug) (1.9.3)\n",
      "Requirement already satisfied: Pillow in c:\\python311\\lib\\site-packages (from imgaug) (9.4.0)\n",
      "Requirement already satisfied: matplotlib in c:\\python311\\lib\\site-packages (from imgaug) (3.6.2)\n",
      "Requirement already satisfied: scikit-image>=0.14.2 in c:\\python311\\lib\\site-packages (from imgaug) (0.20.0)\n",
      "Requirement already satisfied: opencv-python in c:\\python311\\lib\\site-packages (from imgaug) (4.7.0.72)\n",
      "Requirement already satisfied: imageio in c:\\python311\\lib\\site-packages (from imgaug) (2.28.0)\n",
      "Requirement already satisfied: Shapely in c:\\python311\\lib\\site-packages (from imgaug) (2.0.2)\n",
      "Requirement already satisfied: networkx>=2.8 in c:\\python311\\lib\\site-packages (from scikit-image>=0.14.2->imgaug) (3.1)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in c:\\python311\\lib\\site-packages (from scikit-image>=0.14.2->imgaug) (2023.4.12)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in c:\\python311\\lib\\site-packages (from scikit-image>=0.14.2->imgaug) (1.4.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\omarpc\\appdata\\roaming\\python\\python311\\site-packages (from scikit-image>=0.14.2->imgaug) (21.3)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in c:\\python311\\lib\\site-packages (from scikit-image>=0.14.2->imgaug) (0.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\python311\\lib\\site-packages (from matplotlib->imgaug) (1.0.6)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\python311\\lib\\site-packages (from matplotlib->imgaug) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\python311\\lib\\site-packages (from matplotlib->imgaug) (4.38.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\python311\\lib\\site-packages (from matplotlib->imgaug) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\omarpc\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib->imgaug) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\omarpc\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib->imgaug) (2.8.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 16, 16, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 16, 16, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 8, 8, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 8, 8, 32)          9248      \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 4, 4, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 4, 4, 64)          18496     \n",
      "                                                                 \n",
      " global_max_pooling2d_1 (Glo  (None, 64)               0         \n",
      " balMaxPooling2D)                                                \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 47,498\n",
      "Trainable params: 47,498\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model info: \n",
      " None\n",
      "Epoch 1/100\n",
      "40/40 [==============================] - 20s 441ms/step - loss: 4.5273 - accuracy: 0.1272 - val_loss: 2.2504 - val_accuracy: 0.1628\n",
      "Epoch 2/100\n",
      "40/40 [==============================] - 16s 420ms/step - loss: 2.1135 - accuracy: 0.2096 - val_loss: 2.1595 - val_accuracy: 0.2133\n",
      "Epoch 3/100\n",
      "40/40 [==============================] - 17s 424ms/step - loss: 1.9508 - accuracy: 0.2664 - val_loss: 2.2775 - val_accuracy: 0.1979\n",
      "Epoch 4/100\n",
      "40/40 [==============================] - 18s 451ms/step - loss: 1.8188 - accuracy: 0.3480 - val_loss: 2.0680 - val_accuracy: 0.2489\n",
      "Epoch 5/100\n",
      "40/40 [==============================] - 17s 425ms/step - loss: 1.6373 - accuracy: 0.4240 - val_loss: 2.0177 - val_accuracy: 0.2925\n",
      "Epoch 6/100\n",
      "40/40 [==============================] - 18s 459ms/step - loss: 1.5330 - accuracy: 0.4664 - val_loss: 2.0058 - val_accuracy: 0.3038\n",
      "Epoch 7/100\n",
      "40/40 [==============================] - 16s 410ms/step - loss: 1.4222 - accuracy: 0.4944 - val_loss: 1.8929 - val_accuracy: 0.3406\n",
      "Epoch 8/100\n",
      "40/40 [==============================] - 18s 461ms/step - loss: 1.3161 - accuracy: 0.5248 - val_loss: 1.9433 - val_accuracy: 0.3398\n",
      "Epoch 9/100\n",
      "40/40 [==============================] - 16s 409ms/step - loss: 1.1749 - accuracy: 0.5936 - val_loss: 1.8892 - val_accuracy: 0.3571\n",
      "Epoch 10/100\n",
      "40/40 [==============================] - 17s 423ms/step - loss: 0.9762 - accuracy: 0.6752 - val_loss: 1.9660 - val_accuracy: 0.3574\n",
      "Epoch 11/100\n",
      "40/40 [==============================] - 17s 436ms/step - loss: 0.9217 - accuracy: 0.6848 - val_loss: 2.0820 - val_accuracy: 0.3521\n",
      "Epoch 12/100\n",
      "40/40 [==============================] - 18s 455ms/step - loss: 0.7496 - accuracy: 0.7520 - val_loss: 2.5018 - val_accuracy: 0.3176\n",
      "Epoch 13/100\n",
      "40/40 [==============================] - 16s 410ms/step - loss: 1.0058 - accuracy: 0.6568 - val_loss: 2.3209 - val_accuracy: 0.3218\n",
      "Epoch 14/100\n",
      "40/40 [==============================] - 16s 414ms/step - loss: 0.7290 - accuracy: 0.7488 - val_loss: 2.4739 - val_accuracy: 0.3448\n",
      "Epoch 15/100\n",
      "40/40 [==============================] - 16s 408ms/step - loss: 0.6487 - accuracy: 0.7728 - val_loss: 2.3850 - val_accuracy: 0.3444\n",
      "Epoch 16/100\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.4525 - accuracy: 0.8582"
     ]
    }
   ],
   "source": [
    "%pip install imgaug\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from imgaug import augmenters as iaa\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout, BatchNormalization, GlobalMaxPooling2D\n",
    "\n",
    "\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "(xtr, ytr), (xtst, ytst) = cifar10.load_data()\n",
    "xeval, xtr, yeval, ytr = train_test_split(  xtr, ytr, test_size= 1000, random_state= 42 )\n",
    "  \n",
    "\n",
    "# augment 25% of data and append it to train set(reform some of image to widen the range of cases that model will see)\n",
    "num_subset = 0.25 * ytr.shape[0]\n",
    "\n",
    "rand_subset_indices = np.random.choice(ytr.shape[0], int(num_subset), replace=False)\n",
    "image_subset = xtr[rand_subset_indices]\n",
    "lables_subset = ytr[rand_subset_indices]\n",
    "\n",
    "\n",
    "seq = iaa.Sequential([\n",
    "   iaa.Fliplr(0.5), #horizental\n",
    "   iaa.Crop(percent=(0, 0.1)),\n",
    "   iaa.Sometimes(\n",
    "      0.5,\n",
    "      iaa.GaussianBlur(sigma=(0, 0.5))\n",
    "   ),\n",
    "   iaa.LinearContrast((0.75, 1.5)),\n",
    "   iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5),\n",
    "   iaa.Multiply((0.8, 1.2), per_channel=0.2)\n",
    "  ], random_order= True)\n",
    "\n",
    "augmented_subset = seq(images= image_subset)\n",
    "\n",
    "#get the old images with new augmanted images (50k + 12.5k images)\n",
    "xtr = np.concatenate((xtr, augmented_subset), axis= 0)\n",
    "ytr = np.concatenate((ytr, lables_subset), axis= 0)\n",
    "\n",
    "\n",
    "# Build Accuracy focused CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3,3), activation= 'relu', padding= 'same', input_shape= (32, 32, 3)))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Conv2D(32, (3,3), activation= 'relu', padding='same'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Conv2D(32, (3,3), activation= 'relu', padding='same'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Conv2D(64, (3,3), activation= 'relu', padding='same'))\n",
    "model.add(GlobalMaxPooling2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation= 'relu'))\n",
    "model.add(Dense(10, activation= 'softmax'))\n",
    "\n",
    "print (f\"Model info: \\n {model.summary()}\")\n",
    "\n",
    "#run model and get the results\n",
    "model.compile(optimizer= 'adam', loss= 'sparse_categorical_crossentropy', metrics= ['accuracy'])\n",
    "model.fit(xtr, ytr, epochs= 100, validation_data=(xeval, yeval))\n",
    "tst_loss, tst_accuracy = model.evaluate(xtst, ytst)\n",
    "\n",
    "#print result and save model weights\n",
    "print(f\"Model Performance Result(loss,accuracy): \\n {tst_loss,tst_accuracy}\")\n",
    "model.save(r\"./assig5_model_data/assig5_modelV4.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
