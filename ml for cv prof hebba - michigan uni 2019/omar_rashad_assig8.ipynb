{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # **Name:** _Omar Rashad Salem_\n",
    "> # **Course:** _ML&CV - prof.Heba_\n",
    "> # **Assignemnt No.:** _8_\n",
    "\n",
    "> ## QUESTIONS\n",
    "\n",
    "##### _1)_ **What is the main issue with vanilla RNNs when dealing with long-term dependencies in sequences?**\n",
    "\n",
    "**ans:** \n",
    "Vanilla RNNs struggle with long-term dependencies because vanishing gradients during backpropagation prevent them from remembering distant information.  Newer architectures like LSTMs overcome this limitation.\n",
    "\n",
    "##### _2)_ **explain the purpose of the attention mechanism in neural networks. How does it enhance the model's ability to process sequential or spatial data?**\n",
    "\n",
    "**ans:** \n",
    "Attention spotlights relevant parts of data (words, pixels) for enhanced processing: - Sequences: remembers distant words by dynamically weighting their importance. - Spatial data: focuses on key regions and ignores background noise.\n",
    "\n",
    "##### _3)_ **In a sequence-to-sequence model with attention, if the encoder processes a sequence of length 10 and the decoder generates a sequence of length 8, how many alignment scores need to be computed in total?**\n",
    "\n",
    "**ans:** \n",
    "80 alignment scores are computed\n",
    "\n",
    "##### _4)_ **Break down the four components of a Long Short-Term Memory (LSTM) cell. How does each component contribute to addressing the challenges of learning long-term dependencies?**\n",
    "\n",
    "**ans:** \n",
    "* Cell State & Forget Gate: Together, they filter and preserve long-term dependencies, like remembering the main plot points of a story, even after reading for hours.\n",
    "\n",
    "* Input & Output Gates: These regulate the flow of information, ensuring only relevant updates enter and crucial insights leave, preventing distractions and focusing on what matters.\n",
    "\n",
    "##### _5)_ **If you were to visualize attention weights in a sequence-to-sequence model, what would high attention weights indicate? How does attention help the model focus on relevant parts of the input sequence during decoding?**\n",
    "\n",
    "**ans:** \n",
    "High attention weights in a sequence-to-sequence model light up the most relevant parts of the input sequence, like a spotlight guiding the model's focus during decoding.\n",
    "\n",
    "This selective focus improves accuracy and context-awareness in tasks like translation and text summarization.\n",
    "\n",
    "##### _6)_ **Describe the role of Region Proposal Networks (RPNs) in object detection frameworks like Faster R-CNN?**\n",
    "\n",
    "**ans:** \n",
    "\n",
    "RPNs act as treasure hunters in Faster R-CNN, scanning images for promising object locations with \"objectness scores\" and suggesting bounding boxes for closer inspection.\n",
    "\n",
    "##### _7)_ **How does semantic segmentation differ from object detection?**\n",
    "\n",
    "**ans:** \n",
    "Semantic segmentation meticulously paints each pixel with its class, while object detection draws rough outlines around distinct objects.\n",
    "\n",
    "##### _8)_ **Describe the idea behind using fully convolutional networks for semantic segmentation. How do these networks differ from traditional convolutional networks in handling segmentation tasks?**\n",
    "\n",
    "**ans:** \n",
    "FCNs ditch final fully-connected layers for convolutions, letting them process any size image and maintain pixel-level detail. This unlocks tasks like street scene labeling where each pixel gets its own \"color\" (semantic category). Think of it as coloring a detailed map instead of the whole thing with one color. Bye-bye fixed input sizes, hello detailed pixel-wise segmentation!\n",
    "\n",
    "----\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
