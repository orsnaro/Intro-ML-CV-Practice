{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # **Name:** _Omar Rashad Salem_\n",
    "> # **Course:** _CV - prof.Heba_\n",
    "> # **Assignemnt No.:** _4_\n",
    "\n",
    "> ## QUESTIONS\n",
    "\n",
    "##### _1)_ **What is a Convolutional Neural Network (CNN) and what makes it suitable for image-related tasks?**\n",
    "\n",
    "**ans:** \n",
    "- CNN  is type of neural networks that is used for processing  a higher dimensional type of data or cluster of data like images e.g.(rgb / gray scale) it posseses the ability to learn  patterns and hierarchical\n",
    " representations\n",
    "----\n",
    "\n",
    "##### _2)_ **Explain the concept of local connectivity in CNNs.**\n",
    "\n",
    "**ans:**  output of neuron in a X layer connects only to a small local region in the next layer that mostly share some similar context.  this effectively reduces `CNN` complexity and optimizes it!\n",
    "\n",
    "----\n",
    "##### _3)_ **What are the key parameters of a Convolutional Layer?**\n",
    "\n",
    "**ans:** \n",
    "- No. of filters `K`\n",
    "- Stride `S`\n",
    "- Filter size `F`\n",
    "- Zero padding `P`\n",
    "\n",
    "\n",
    "----\n",
    "##### _4)_ **Why is zero-padding used in Convolutional Layers, and what impact does it have on the spatial arrangement?**\n",
    "\n",
    "**ans:**\n",
    "- preserves the input dimensions / makes it managable\n",
    "- marks the edges of an images which could come very handy in image processing and computer vision\n",
    "\n",
    "----\n",
    "##### _5)_ **What is the purpose of pooling layer in ConvNet?**\n",
    "\n",
    "\n",
    "**ans:** \n",
    "- reduces the dimensions and parameters which helps boosting CNN over all performance and computing time\n",
    "- produces no extra parameters \n",
    "\n",
    "\n",
    "----\n",
    "##### _6)_ **SOLVE**\n",
    "given:\n",
    "\n",
    "\t\t- filter size = 2x2\n",
    " \t\t- stride = 2\n",
    "\t\t- i/p size = 28x28x64\n",
    "\t\t- it's a pooling layer\n",
    "\n",
    "* Find o/p Volume?\n",
    "\n",
    "**ans:** \n",
    "$$\n",
    "\tW = (w - f)/s + 1\n",
    "\t\\\\\n",
    "\tW = (16 - 2) / 2 + 1\n",
    "\t\\\\\n",
    "\t\\therefore W = 14\n",
    "\t\\\\\n",
    "\to/p-Volume = 14 * 14 * 64\n",
    "\t\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "----\n",
    "##### _7)_ **SOLVE**\n",
    "\n",
    "given:\n",
    "\n",
    "\t\t- filter size = 3x3\n",
    "\t\t- filters No. = 32\n",
    " \t\t- stride = 1\n",
    "\t\t- i/p size = 32x32x3\n",
    "\t\t- it's a Convolution layer\n",
    "\n",
    "* Find o/p Volume?\n",
    "\n",
    "**ans:** \n",
    "$$\n",
    "\tW = (w - f + 2p)/s + 1\n",
    "\t\\\\\n",
    "\tW = (32 - 3 + 2*0) / 1 + 1\n",
    "\t\\\\\n",
    "\t\\therefore W = 30\n",
    "\t\\\\\n",
    "\to/p-Volume = 30 * 30 * 32\n",
    "\t\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "----\n",
    "##### _8)_ **SOLVE**\n",
    "\n",
    "given:\n",
    "\n",
    "\t\t- filter size = 3x3\n",
    "\t\t- filters No. = 8\n",
    " \t\t\n",
    "* Find No. of parameters including biases?\n",
    "\n",
    "**ans:** \n",
    "$$\n",
    "\tNo.parameters = filter'size * depth * biases\n",
    "\t\\\\\n",
    "\t= 3 * 3 * 3 + 1 \n",
    "\t\\\\\n",
    "\to/p-Volume = 28 \n",
    "\t\\\\\n",
    "\t\\therefore No.parameters = 28*8 = 224\n",
    "$$\n",
    "\n",
    "\n",
    "----\n",
    "##### _9)_ **SOLVE**\n",
    "\n",
    "given:\n",
    "\n",
    "\t\t- i/p volume = 256*256*3\n",
    "\t\t- layer neurons no. = 100\n",
    " \t\t\n",
    "* Find No. weights and biases needed?\n",
    "\n",
    "**ans:** \n",
    "$$\n",
    "\tweights = 256*256*3*100 \n",
    "\t\\\\\n",
    "\tweights = 19660800\n",
    "\t\\\\\n",
    "\tbiases = 1*100 = 100\n",
    "$$\n",
    "\n",
    "\n",
    "----\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Programming Assignment _(challenge task!)_: \n",
    "> #### Image Classification using Convolutional Neural Networks (ConvNet)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # Code for accuracy FOCUSED CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imgaug in c:\\python311\\lib\\site-packages (0.4.0)\n",
      "Requirement already satisfied: six in c:\\python311\\lib\\site-packages (from imgaug) (1.16.0)\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\python311\\lib\\site-packages (from imgaug) (1.23.5)\n",
      "Requirement already satisfied: scipy in c:\\python311\\lib\\site-packages (from imgaug) (1.9.3)\n",
      "Requirement already satisfied: Pillow in c:\\python311\\lib\\site-packages (from imgaug) (9.4.0)\n",
      "Requirement already satisfied: matplotlib in c:\\python311\\lib\\site-packages (from imgaug) (3.6.2)\n",
      "Requirement already satisfied: scikit-image>=0.14.2 in c:\\python311\\lib\\site-packages (from imgaug) (0.20.0)\n",
      "Requirement already satisfied: opencv-python in c:\\python311\\lib\\site-packages (from imgaug) (4.7.0.72)\n",
      "Requirement already satisfied: imageio in c:\\python311\\lib\\site-packages (from imgaug) (2.28.0)\n",
      "Requirement already satisfied: Shapely in c:\\python311\\lib\\site-packages (from imgaug) (2.0.2)\n",
      "Requirement already satisfied: networkx>=2.8 in c:\\python311\\lib\\site-packages (from scikit-image>=0.14.2->imgaug) (3.1)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in c:\\python311\\lib\\site-packages (from scikit-image>=0.14.2->imgaug) (2023.4.12)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in c:\\python311\\lib\\site-packages (from scikit-image>=0.14.2->imgaug) (1.4.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\omarpc\\appdata\\roaming\\python\\python311\\site-packages (from scikit-image>=0.14.2->imgaug) (21.3)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in c:\\python311\\lib\\site-packages (from scikit-image>=0.14.2->imgaug) (0.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\python311\\lib\\site-packages (from matplotlib->imgaug) (1.0.6)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\python311\\lib\\site-packages (from matplotlib->imgaug) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\python311\\lib\\site-packages (from matplotlib->imgaug) (4.38.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\python311\\lib\\site-packages (from matplotlib->imgaug) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\omarpc\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib->imgaug) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\omarpc\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib->imgaug) (2.8.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\python311\\lib\\site-packages\\vboxapi-1.0-py3.11.egg is deprecated. pip 23.3 will enforce this behaviour change. A possible replacement is to use pip for package installation..\n",
      "DEPRECATION: textract 1.6.5 has a non-standard dependency specifier extract-msg<=0.29.*. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of textract or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 16, 16, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 16, 16, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 8, 8, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 8, 8, 32)          9248      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 4, 4, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 4, 4, 64)          18496     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               131200    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 170,378\n",
      "Trainable params: 170,378\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model info: \n",
      " None\n",
      "Epoch 1/100\n",
      "32/32 [==============================] - 40s 1s/step - loss: 5.7741 - accuracy: 0.1360 - val_loss: 2.1738 - val_accuracy: 0.2156\n",
      "Epoch 2/100\n",
      "32/32 [==============================] - 29s 948ms/step - loss: 2.0336 - accuracy: 0.2840 - val_loss: 2.0896 - val_accuracy: 0.2509\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - 28s 916ms/step - loss: 1.7719 - accuracy: 0.3850 - val_loss: 2.1195 - val_accuracy: 0.2751\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - 33s 1s/step - loss: 1.5575 - accuracy: 0.4520 - val_loss: 1.9118 - val_accuracy: 0.3366\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - 32s 1s/step - loss: 1.3975 - accuracy: 0.5260 - val_loss: 2.1642 - val_accuracy: 0.3047\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - 29s 949ms/step - loss: 1.3223 - accuracy: 0.5400 - val_loss: 1.8648 - val_accuracy: 0.3731\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - 31s 993ms/step - loss: 1.1277 - accuracy: 0.6080 - val_loss: 1.9745 - val_accuracy: 0.3476\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - 31s 992ms/step - loss: 0.9407 - accuracy: 0.6940 - val_loss: 1.9565 - val_accuracy: 0.3716\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - 32s 1s/step - loss: 0.7994 - accuracy: 0.7410 - val_loss: 2.0392 - val_accuracy: 0.3771\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - 29s 919ms/step - loss: 0.6338 - accuracy: 0.7830 - val_loss: 2.2095 - val_accuracy: 0.3768\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - 29s 929ms/step - loss: 0.4751 - accuracy: 0.8470 - val_loss: 2.3401 - val_accuracy: 0.3793\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - 29s 927ms/step - loss: 0.3555 - accuracy: 0.8920 - val_loss: 2.4083 - val_accuracy: 0.3823\n",
      "Epoch 13/100\n",
      "32/32 [==============================] - 28s 900ms/step - loss: 0.3295 - accuracy: 0.8950 - val_loss: 2.5628 - val_accuracy: 0.3853\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - 31s 1s/step - loss: 0.3206 - accuracy: 0.8950 - val_loss: 2.6980 - val_accuracy: 0.3532\n",
      "Epoch 15/100\n",
      "32/32 [==============================] - 29s 945ms/step - loss: 0.2167 - accuracy: 0.9390 - val_loss: 2.8200 - val_accuracy: 0.3840\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - 31s 1s/step - loss: 0.1236 - accuracy: 0.9650 - val_loss: 3.1812 - val_accuracy: 0.3857\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - 29s 939ms/step - loss: 0.0876 - accuracy: 0.9800 - val_loss: 2.9565 - val_accuracy: 0.3962\n",
      "Epoch 18/100\n",
      "32/32 [==============================] - 31s 993ms/step - loss: 0.0453 - accuracy: 0.9950 - val_loss: 3.3910 - val_accuracy: 0.3927\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - 27s 873ms/step - loss: 0.0432 - accuracy: 0.9940 - val_loss: 3.4644 - val_accuracy: 0.3965\n",
      "Epoch 20/100\n",
      "32/32 [==============================] - 28s 909ms/step - loss: 0.0229 - accuracy: 0.9980 - val_loss: 3.5937 - val_accuracy: 0.3974\n",
      "Epoch 21/100\n",
      "32/32 [==============================] - 29s 935ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 3.6313 - val_accuracy: 0.4046\n",
      "Epoch 22/100\n",
      "32/32 [==============================] - 28s 901ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 3.6795 - val_accuracy: 0.4045\n",
      "Epoch 23/100\n",
      "32/32 [==============================] - 29s 941ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 3.7498 - val_accuracy: 0.4065\n",
      "Epoch 24/100\n",
      "32/32 [==============================] - 27s 861ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 3.8234 - val_accuracy: 0.4068\n",
      "Epoch 25/100\n",
      "32/32 [==============================] - 30s 952ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.8878 - val_accuracy: 0.4079\n",
      "Epoch 26/100\n",
      "32/32 [==============================] - 29s 926ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.9293 - val_accuracy: 0.4074\n",
      "Epoch 27/100\n",
      "32/32 [==============================] - 29s 938ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.9795 - val_accuracy: 0.4075\n",
      "Epoch 28/100\n",
      "32/32 [==============================] - 29s 938ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 4.0144 - val_accuracy: 0.4078\n",
      "Epoch 29/100\n",
      "32/32 [==============================] - 27s 882ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 4.0618 - val_accuracy: 0.4079\n",
      "Epoch 30/100\n",
      "32/32 [==============================] - 30s 953ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 4.0980 - val_accuracy: 0.4080\n",
      "Epoch 31/100\n",
      "32/32 [==============================] - 28s 916ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 4.1240 - val_accuracy: 0.4075\n",
      "Epoch 32/100\n",
      "32/32 [==============================] - 30s 965ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 4.1533 - val_accuracy: 0.4076\n",
      "Epoch 33/100\n",
      "32/32 [==============================] - 27s 880ms/step - loss: 9.5484e-04 - accuracy: 1.0000 - val_loss: 4.1854 - val_accuracy: 0.4085\n",
      "Epoch 34/100\n",
      "32/32 [==============================] - 30s 952ms/step - loss: 8.7848e-04 - accuracy: 1.0000 - val_loss: 4.2112 - val_accuracy: 0.4081\n",
      "Epoch 35/100\n",
      "32/32 [==============================] - 30s 954ms/step - loss: 8.2727e-04 - accuracy: 1.0000 - val_loss: 4.2423 - val_accuracy: 0.4086\n",
      "Epoch 36/100\n",
      "32/32 [==============================] - 29s 919ms/step - loss: 7.7777e-04 - accuracy: 1.0000 - val_loss: 4.2692 - val_accuracy: 0.4086\n",
      "Epoch 37/100\n",
      "32/32 [==============================] - 31s 994ms/step - loss: 7.3020e-04 - accuracy: 1.0000 - val_loss: 4.2996 - val_accuracy: 0.4088\n",
      "Epoch 38/100\n",
      "32/32 [==============================] - 32s 1s/step - loss: 6.8543e-04 - accuracy: 1.0000 - val_loss: 4.3217 - val_accuracy: 0.4084\n",
      "Epoch 39/100\n",
      "32/32 [==============================] - 32s 1s/step - loss: 6.4850e-04 - accuracy: 1.0000 - val_loss: 4.3399 - val_accuracy: 0.4085\n",
      "Epoch 40/100\n",
      "32/32 [==============================] - 30s 962ms/step - loss: 6.2184e-04 - accuracy: 1.0000 - val_loss: 4.3713 - val_accuracy: 0.4083\n",
      "Epoch 41/100\n",
      "32/32 [==============================] - 31s 1s/step - loss: 5.8260e-04 - accuracy: 1.0000 - val_loss: 4.3834 - val_accuracy: 0.4092\n",
      "Epoch 42/100\n",
      "32/32 [==============================] - 30s 950ms/step - loss: 5.5428e-04 - accuracy: 1.0000 - val_loss: 4.4117 - val_accuracy: 0.4090\n",
      "Epoch 43/100\n",
      "32/32 [==============================] - 31s 999ms/step - loss: 5.2625e-04 - accuracy: 1.0000 - val_loss: 4.4286 - val_accuracy: 0.4089\n",
      "Epoch 44/100\n",
      "32/32 [==============================] - 31s 1s/step - loss: 5.0087e-04 - accuracy: 1.0000 - val_loss: 4.4485 - val_accuracy: 0.4091\n",
      "Epoch 45/100\n",
      "32/32 [==============================] - 29s 928ms/step - loss: 4.7545e-04 - accuracy: 1.0000 - val_loss: 4.4769 - val_accuracy: 0.4097\n",
      "Epoch 46/100\n",
      "32/32 [==============================] - 30s 963ms/step - loss: 4.5089e-04 - accuracy: 1.0000 - val_loss: 4.4909 - val_accuracy: 0.4090\n",
      "Epoch 47/100\n",
      "32/32 [==============================] - 29s 945ms/step - loss: 4.3198e-04 - accuracy: 1.0000 - val_loss: 4.5113 - val_accuracy: 0.4092\n",
      "Epoch 48/100\n",
      "32/32 [==============================] - 30s 972ms/step - loss: 4.1332e-04 - accuracy: 1.0000 - val_loss: 4.5329 - val_accuracy: 0.4090\n",
      "Epoch 49/100\n",
      "32/32 [==============================] - 29s 947ms/step - loss: 3.9506e-04 - accuracy: 1.0000 - val_loss: 4.5462 - val_accuracy: 0.4094\n",
      "Epoch 50/100\n",
      "32/32 [==============================] - 31s 982ms/step - loss: 3.7733e-04 - accuracy: 1.0000 - val_loss: 4.5646 - val_accuracy: 0.4094\n",
      "Epoch 51/100\n",
      "32/32 [==============================] - 30s 967ms/step - loss: 3.6090e-04 - accuracy: 1.0000 - val_loss: 4.5902 - val_accuracy: 0.4088\n",
      "Epoch 52/100\n",
      "32/32 [==============================] - 29s 928ms/step - loss: 3.4729e-04 - accuracy: 1.0000 - val_loss: 4.6040 - val_accuracy: 0.4092\n",
      "Epoch 53/100\n",
      "32/32 [==============================] - 28s 909ms/step - loss: 3.3218e-04 - accuracy: 1.0000 - val_loss: 4.6240 - val_accuracy: 0.4096\n",
      "Epoch 54/100\n",
      "32/32 [==============================] - 27s 874ms/step - loss: 3.1679e-04 - accuracy: 1.0000 - val_loss: 4.6391 - val_accuracy: 0.4096\n",
      "Epoch 55/100\n",
      "32/32 [==============================] - 35s 1s/step - loss: 3.0617e-04 - accuracy: 1.0000 - val_loss: 4.6533 - val_accuracy: 0.4092\n",
      "Epoch 56/100\n",
      "32/32 [==============================] - 31s 999ms/step - loss: 2.9605e-04 - accuracy: 1.0000 - val_loss: 4.6749 - val_accuracy: 0.4096\n",
      "Epoch 57/100\n",
      "32/32 [==============================] - 34s 1s/step - loss: 2.8204e-04 - accuracy: 1.0000 - val_loss: 4.6878 - val_accuracy: 0.4097\n",
      "Epoch 58/100\n",
      "32/32 [==============================] - 33s 1s/step - loss: 2.7181e-04 - accuracy: 1.0000 - val_loss: 4.7045 - val_accuracy: 0.4092\n",
      "Epoch 59/100\n",
      "32/32 [==============================] - 30s 981ms/step - loss: 2.6303e-04 - accuracy: 1.0000 - val_loss: 4.7179 - val_accuracy: 0.4096\n",
      "Epoch 60/100\n",
      "32/32 [==============================] - 33s 1s/step - loss: 2.5271e-04 - accuracy: 1.0000 - val_loss: 4.7328 - val_accuracy: 0.4094\n",
      "Epoch 61/100\n",
      "32/32 [==============================] - 30s 978ms/step - loss: 2.4333e-04 - accuracy: 1.0000 - val_loss: 4.7489 - val_accuracy: 0.4096\n",
      "Epoch 62/100\n",
      "32/32 [==============================] - 33s 1s/step - loss: 2.3607e-04 - accuracy: 1.0000 - val_loss: 4.7641 - val_accuracy: 0.4095\n",
      "Epoch 63/100\n",
      "32/32 [==============================] - 30s 974ms/step - loss: 2.2774e-04 - accuracy: 1.0000 - val_loss: 4.7751 - val_accuracy: 0.4100\n",
      "Epoch 64/100\n",
      "32/32 [==============================] - 31s 1s/step - loss: 2.2060e-04 - accuracy: 1.0000 - val_loss: 4.7925 - val_accuracy: 0.4093\n",
      "Epoch 65/100\n",
      "32/32 [==============================] - 32s 1s/step - loss: 2.1199e-04 - accuracy: 1.0000 - val_loss: 4.8055 - val_accuracy: 0.4098\n",
      "Epoch 66/100\n",
      "32/32 [==============================] - 30s 976ms/step - loss: 2.0589e-04 - accuracy: 1.0000 - val_loss: 4.8215 - val_accuracy: 0.4098\n",
      "Epoch 67/100\n",
      "32/32 [==============================] - 29s 936ms/step - loss: 2.0023e-04 - accuracy: 1.0000 - val_loss: 4.8340 - val_accuracy: 0.4096\n",
      "Epoch 68/100\n",
      "32/32 [==============================] - 26s 846ms/step - loss: 1.9262e-04 - accuracy: 1.0000 - val_loss: 4.8489 - val_accuracy: 0.4099\n",
      "Epoch 69/100\n",
      "32/32 [==============================] - 28s 897ms/step - loss: 1.8735e-04 - accuracy: 1.0000 - val_loss: 4.8591 - val_accuracy: 0.4095\n",
      "Epoch 70/100\n",
      "32/32 [==============================] - 27s 854ms/step - loss: 1.8126e-04 - accuracy: 1.0000 - val_loss: 4.8753 - val_accuracy: 0.4097\n",
      "Epoch 71/100\n",
      "32/32 [==============================] - 29s 927ms/step - loss: 1.7464e-04 - accuracy: 1.0000 - val_loss: 4.8883 - val_accuracy: 0.4099\n",
      "Epoch 72/100\n",
      "32/32 [==============================] - 29s 942ms/step - loss: 1.6932e-04 - accuracy: 1.0000 - val_loss: 4.8974 - val_accuracy: 0.4097\n",
      "Epoch 73/100\n",
      "32/32 [==============================] - 28s 900ms/step - loss: 1.6413e-04 - accuracy: 1.0000 - val_loss: 4.9112 - val_accuracy: 0.4098\n",
      "Epoch 74/100\n",
      "32/32 [==============================] - 35s 1s/step - loss: 1.5975e-04 - accuracy: 1.0000 - val_loss: 4.9227 - val_accuracy: 0.4097\n",
      "Epoch 75/100\n",
      "32/32 [==============================] - 32s 1s/step - loss: 1.5474e-04 - accuracy: 1.0000 - val_loss: 4.9404 - val_accuracy: 0.4101\n",
      "Epoch 76/100\n",
      "32/32 [==============================] - 33s 1s/step - loss: 1.4970e-04 - accuracy: 1.0000 - val_loss: 4.9483 - val_accuracy: 0.4097\n",
      "Epoch 77/100\n",
      "32/32 [==============================] - 30s 967ms/step - loss: 1.4572e-04 - accuracy: 1.0000 - val_loss: 4.9608 - val_accuracy: 0.4098\n",
      "Epoch 78/100\n",
      "32/32 [==============================] - 32s 1s/step - loss: 1.4165e-04 - accuracy: 1.0000 - val_loss: 4.9745 - val_accuracy: 0.4098\n",
      "Epoch 79/100\n",
      "32/32 [==============================] - 30s 967ms/step - loss: 1.3752e-04 - accuracy: 1.0000 - val_loss: 4.9899 - val_accuracy: 0.4101\n",
      "Epoch 80/100\n",
      "32/32 [==============================] - 30s 966ms/step - loss: 1.3348e-04 - accuracy: 1.0000 - val_loss: 4.9975 - val_accuracy: 0.4096\n",
      "Epoch 81/100\n",
      "32/32 [==============================] - 32s 1s/step - loss: 1.3037e-04 - accuracy: 1.0000 - val_loss: 5.0084 - val_accuracy: 0.4101\n",
      "Epoch 82/100\n",
      "32/32 [==============================] - 30s 979ms/step - loss: 1.2587e-04 - accuracy: 1.0000 - val_loss: 5.0202 - val_accuracy: 0.4098\n",
      "Epoch 83/100\n",
      "32/32 [==============================] - 33s 1s/step - loss: 1.2252e-04 - accuracy: 1.0000 - val_loss: 5.0318 - val_accuracy: 0.4099\n",
      "Epoch 84/100\n",
      "32/32 [==============================] - 31s 1s/step - loss: 1.1896e-04 - accuracy: 1.0000 - val_loss: 5.0416 - val_accuracy: 0.4098\n",
      "Epoch 85/100\n",
      "32/32 [==============================] - 34s 1s/step - loss: 1.1619e-04 - accuracy: 1.0000 - val_loss: 5.0557 - val_accuracy: 0.4101\n",
      "Epoch 86/100\n",
      "32/32 [==============================] - 33s 1s/step - loss: 1.1250e-04 - accuracy: 1.0000 - val_loss: 5.0647 - val_accuracy: 0.4097\n",
      "Epoch 87/100\n",
      "32/32 [==============================] - 33s 1s/step - loss: 1.0965e-04 - accuracy: 1.0000 - val_loss: 5.0792 - val_accuracy: 0.4101\n",
      "Epoch 88/100\n",
      "32/32 [==============================] - 35s 1s/step - loss: 1.0727e-04 - accuracy: 1.0000 - val_loss: 5.0900 - val_accuracy: 0.4099\n",
      "Epoch 89/100\n",
      "32/32 [==============================] - 31s 994ms/step - loss: 1.0410e-04 - accuracy: 1.0000 - val_loss: 5.1008 - val_accuracy: 0.4104\n",
      "Epoch 90/100\n",
      "32/32 [==============================] - 32s 1s/step - loss: 1.0094e-04 - accuracy: 1.0000 - val_loss: 5.1108 - val_accuracy: 0.4102\n",
      "Epoch 91/100\n",
      "32/32 [==============================] - 29s 925ms/step - loss: 9.8492e-05 - accuracy: 1.0000 - val_loss: 5.1219 - val_accuracy: 0.4101\n",
      "Epoch 92/100\n",
      "32/32 [==============================] - 31s 1s/step - loss: 9.5985e-05 - accuracy: 1.0000 - val_loss: 5.1348 - val_accuracy: 0.4100\n",
      "Epoch 93/100\n",
      "32/32 [==============================] - 30s 981ms/step - loss: 9.3769e-05 - accuracy: 1.0000 - val_loss: 5.1433 - val_accuracy: 0.4099\n",
      "Epoch 94/100\n",
      "32/32 [==============================] - 28s 915ms/step - loss: 9.1079e-05 - accuracy: 1.0000 - val_loss: 5.1533 - val_accuracy: 0.4099\n",
      "Epoch 95/100\n",
      "32/32 [==============================] - 28s 917ms/step - loss: 8.8877e-05 - accuracy: 1.0000 - val_loss: 5.1629 - val_accuracy: 0.4099\n",
      "Epoch 96/100\n",
      "32/32 [==============================] - 27s 873ms/step - loss: 8.6202e-05 - accuracy: 1.0000 - val_loss: 5.1760 - val_accuracy: 0.4099\n",
      "Epoch 97/100\n",
      "32/32 [==============================] - 29s 932ms/step - loss: 8.4040e-05 - accuracy: 1.0000 - val_loss: 5.1887 - val_accuracy: 0.4098\n",
      "Epoch 98/100\n",
      "32/32 [==============================] - 27s 859ms/step - loss: 8.1636e-05 - accuracy: 1.0000 - val_loss: 5.1990 - val_accuracy: 0.4100\n",
      "Epoch 99/100\n",
      "32/32 [==============================] - 29s 926ms/step - loss: 7.9823e-05 - accuracy: 1.0000 - val_loss: 5.2115 - val_accuracy: 0.4102\n",
      "Epoch 100/100\n",
      "32/32 [==============================] - 28s 892ms/step - loss: 7.7620e-05 - accuracy: 1.0000 - val_loss: 5.2192 - val_accuracy: 0.4098\n",
      "313/313 [==============================] - 6s 20ms/step - loss: 5.1761 - accuracy: 0.4119\n",
      "Model Performance Result(loss,accuracy): \n",
      " (5.1761345863342285, 0.41190001368522644)\n"
     ]
    }
   ],
   "source": [
    "%pip install imgaug\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from imgaug import augmenters as iaa\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout, BatchNormalization, GlobalMaxPooling2D\n",
    "\n",
    "\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "(xtr, ytr), (xtst, ytst) = cifar10.load_data()\n",
    "xeval, xtr, yeval, ytr = train_test_split(  xtr, ytr, test_size= 1000, random_state= 42 )\n",
    "  \n",
    "\n",
    "# # augment 25% of data and append it to train set(reform some of image to widen the range of cases that model will see)\n",
    "# num_subset = 0.25 * ytr.shape[0]\n",
    "\n",
    "# rand_subset_indices = np.random.choice(ytr.shape[0], int(num_subset), replace=False)\n",
    "# image_subset = xtr[rand_subset_indices]\n",
    "# lables_subset = ytr[rand_subset_indices]\n",
    "\n",
    "\n",
    "# seq = iaa.Sequential([\n",
    "#    iaa.Fliplr(0.5), #horizental\n",
    "#    iaa.Crop(percent=(0, 0.1)),\n",
    "#    iaa.Sometimes(\n",
    "#       0.5,\n",
    "#       iaa.GaussianBlur(sigma=(0, 0.5))\n",
    "#    ),\n",
    "#    iaa.LinearContrast((0.75, 1.5)),\n",
    "#    iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5),\n",
    "#    iaa.Multiply((0.8, 1.2), per_channel=0.2),\n",
    "#    iaa.Affine(\n",
    "#       scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},\n",
    "#       translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n",
    "#       rotate=(-10, 10),\n",
    "#       shear=(-8, 8)\n",
    "#    )], random_order= True)\n",
    "\n",
    "# augmented_subset = seq(images= image_subset)\n",
    "\n",
    "# #get the old images with new augmanted images (50k + 12.5k images)\n",
    "# xtr = np.concatenate((xtr, augmented_subset), axis= 0)\n",
    "# ytr = np.concatenate((ytr, lables_subset), axis= 0)\n",
    "\n",
    "\n",
    "# Build Accuracy focused CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3,3), activation= 'relu', padding= 'same', input_shape= (32, 32, 3)))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Conv2D(32, (3,3), activation= 'relu', padding='same'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Conv2D(32, (3,3), activation= 'relu', padding='same'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Conv2D(64, (3,3), activation= 'relu', padding='same'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation= 'relu'))\n",
    "model.add(Dense(10, activation= 'softmax'))\n",
    "\n",
    "print (f\"Model info: \\n {model.summary()}\")\n",
    "\n",
    "#run model and get the results\n",
    "model.compile(optimizer= 'adam', loss= 'sparse_categorical_crossentropy', metrics= ['accuracy'])\n",
    "model.fit(xtr, ytr, epochs= 100, validation_data=(xeval, yeval))\n",
    "tst_loss, tst_accuracy = model.evaluate(xtst, ytst)\n",
    "\n",
    "#print result and save model weights\n",
    "print(f\"Model Performance Result(loss,accuracy): \\n {tst_loss,tst_accuracy}\")\n",
    "model.save(r\"./assig5_model_data/assig5_modelV2.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'pandas' has no attribute 'core' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32me:\\omar-work\\tasks college\\img process prof hebba\\omar_rashad_assig5_P1_v2.ipynb Cell 5\u001b[0m in \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/omar-work/tasks%20college/img%20process%20prof%20hebba/omar_rashad_assig5_P1_v2.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/omar-work/tasks%20college/img%20process%20prof%20hebba/omar_rashad_assig5_P1_v2.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m layers, models\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/omar-work/tasks%20college/img%20process%20prof%20hebba/omar_rashad_assig5_P1_v2.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatasets\u001b[39;00m \u001b[39mimport\u001b[39;00m cifar10\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\tensorflow\\__init__.py:476\u001b[0m\n\u001b[0;32m    474\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(_current_module, \u001b[39m\"\u001b[39m\u001b[39mkeras\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    475\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 476\u001b[0m     _keras\u001b[39m.\u001b[39;49m_load()\n\u001b[0;32m    477\u001b[0m   \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n\u001b[0;32m    478\u001b[0m     \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\lazy_loader.py:41\u001b[0m, in \u001b[0;36mLazyLoader._load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[39m\"\"\"Load the module and insert it into the parent's globals.\"\"\"\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[39m# Import the target module and insert it into the parent's namespace\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m module \u001b[39m=\u001b[39m importlib\u001b[39m.\u001b[39;49mimport_module(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__name__\u001b[39;49m)\n\u001b[0;32m     42\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parent_module_globals[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_local_name] \u001b[39m=\u001b[39m module\n\u001b[0;32m     44\u001b[0m \u001b[39m# Emit a warning if one was specified\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\importlib\\__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    124\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    125\u001b[0m         level \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m--> 126\u001b[0m \u001b[39mreturn\u001b[39;00m _bootstrap\u001b[39m.\u001b[39;49m_gcd_import(name[level:], package, level)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\keras\\__init__.py:21\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[39m\"\"\"Implementation of the Keras API, the high-level API of TensorFlow.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[39mDetailed documentation and user guides are available at\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[39m[keras.io](https://keras.io).\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m distribute\n\u001b[1;32m---> 21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m models\n\u001b[0;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minput_layer\u001b[39;00m \u001b[39mimport\u001b[39;00m Input\n\u001b[0;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msequential\u001b[39;00m \u001b[39mimport\u001b[39;00m Sequential\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\keras\\models\\__init__.py:18\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Copyright 2022 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[39m# ==============================================================================\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[39m\"\"\"Keras models API.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfunctional\u001b[39;00m \u001b[39mimport\u001b[39;00m Functional\n\u001b[0;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msequential\u001b[39;00m \u001b[39mimport\u001b[39;00m Sequential\n\u001b[0;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtraining\u001b[39;00m \u001b[39mimport\u001b[39;00m Model\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\keras\\engine\\functional.py:34\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m input_spec\n\u001b[0;32m     33\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m node \u001b[39mas\u001b[39;00m node_module\n\u001b[1;32m---> 34\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m training \u001b[39mas\u001b[39;00m training_lib\n\u001b[0;32m     35\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m training_utils\n\u001b[0;32m     36\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msaving\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlegacy\u001b[39;00m \u001b[39mimport\u001b[39;00m serialization\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\keras\\engine\\training.py:32\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m base_layer\n\u001b[0;32m     31\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m base_layer_utils\n\u001b[1;32m---> 32\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m compile_utils\n\u001b[0;32m     33\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m data_adapter\n\u001b[0;32m     34\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m input_layer \u001b[39mas\u001b[39;00m input_layer_module\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\keras\\engine\\compile_utils.py:24\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m losses \u001b[39mas\u001b[39;00m losses_mod\n\u001b[1;32m---> 24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m metrics \u001b[39mas\u001b[39;00m metrics_mod\n\u001b[0;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msaving\u001b[39;00m \u001b[39mimport\u001b[39;00m saving_lib\n\u001b[0;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m generic_utils\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\keras\\metrics\\__init__.py:84\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mregression_metrics\u001b[39;00m \u001b[39mimport\u001b[39;00m mean_squared_logarithmic_error\n\u001b[0;32m     83\u001b[0m \u001b[39m# Confusion metrics\u001b[39;00m\n\u001b[1;32m---> 84\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconfusion_metrics\u001b[39;00m \u001b[39mimport\u001b[39;00m AUC\n\u001b[0;32m     85\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconfusion_metrics\u001b[39;00m \u001b[39mimport\u001b[39;00m FalseNegatives\n\u001b[0;32m     86\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconfusion_metrics\u001b[39;00m \u001b[39mimport\u001b[39;00m FalsePositives\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\keras\\metrics\\confusion_metrics.py:22\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m activations\n\u001b[0;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m backend\n\u001b[0;32m     24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdtensor\u001b[39;00m \u001b[39mimport\u001b[39;00m utils \u001b[39mas\u001b[39;00m dtensor_utils\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\keras\\activations.py:21\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mactivation\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mactivation_layers\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m backend\n\u001b[0;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msaving\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlegacy\u001b[39;00m \u001b[39mimport\u001b[39;00m serialization \u001b[39mas\u001b[39;00m legacy_serialization\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\keras\\layers\\__init__.py:20\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbase_layer\u001b[39;00m \u001b[39mimport\u001b[39;00m Layer\n\u001b[1;32m---> 20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbase_preprocessing_layer\u001b[39;00m \u001b[39mimport\u001b[39;00m PreprocessingLayer\n\u001b[0;32m     22\u001b[0m \u001b[39m# Generic layers.\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minput_layer\u001b[39;00m \u001b[39mimport\u001b[39;00m Input\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\keras\\engine\\base_preprocessing_layer.py:21\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mabc\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m data_adapter\n\u001b[0;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbase_layer\u001b[39;00m \u001b[39mimport\u001b[39;00m Layer\n\u001b[0;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m version_utils\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\keras\\engine\\data_adapter.py:44\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtf_export\u001b[39;00m \u001b[39mimport\u001b[39;00m keras_export\n\u001b[0;32m     43\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 44\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n\u001b[0;32m     46\u001b[0m     pd \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\__init__.py:138\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mreshape\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m    121\u001b[0m     concat,\n\u001b[0;32m    122\u001b[0m     lreshape,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    134\u001b[0m     qcut,\n\u001b[0;32m    135\u001b[0m )\n\u001b[0;32m    137\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mimport\u001b[39;00m api, arrays, errors, io, plotting, tseries\n\u001b[1;32m--> 138\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mimport\u001b[39;00m testing  \u001b[39m# noqa:PDF015\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_print_versions\u001b[39;00m \u001b[39mimport\u001b[39;00m show_versions\n\u001b[0;32m    141\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m    142\u001b[0m     \u001b[39m# excel\u001b[39;00m\n\u001b[0;32m    143\u001b[0m     ExcelFile,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    171\u001b[0m     read_spss,\n\u001b[0;32m    172\u001b[0m )\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\testing.py:6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mPublic testing utility functions.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_testing\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m      7\u001b[0m     assert_extension_array_equal,\n\u001b[0;32m      8\u001b[0m     assert_frame_equal,\n\u001b[0;32m      9\u001b[0m     assert_index_equal,\n\u001b[0;32m     10\u001b[0m     assert_series_equal,\n\u001b[0;32m     11\u001b[0m )\n\u001b[0;32m     13\u001b[0m __all__ \u001b[39m=\u001b[39m [\n\u001b[0;32m     14\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39massert_extension_array_equal\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     15\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39massert_frame_equal\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     16\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39massert_series_equal\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     17\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39massert_index_equal\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     18\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\_testing\\__init__.py:903\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mpytest\u001b[39;00m\n\u001b[0;32m    900\u001b[0m     \u001b[39mreturn\u001b[39;00m pytest\u001b[39m.\u001b[39mraises(expected_exception, match\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)  \u001b[39m# noqa: PDF010\u001b[39;00m\n\u001b[1;32m--> 903\u001b[0m cython_table \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mcore\u001b[39m.\u001b[39mcommon\u001b[39m.\u001b[39m_cython_table\u001b[39m.\u001b[39mitems()\n\u001b[0;32m    906\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_cython_table_params\u001b[39m(ndframe, func_names_and_expected):\n\u001b[0;32m    907\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    908\u001b[0m \u001b[39m    Combine frame, functions from com._cython_table\u001b[39;00m\n\u001b[0;32m    909\u001b[0m \u001b[39m    keys and expected result.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    921\u001b[0m \u001b[39m        List of three items (DataFrame, function, expected result)\u001b[39;00m\n\u001b[0;32m    922\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: partially initialized module 'pandas' has no attribute 'core' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
    "\n",
    "# Normalize pixel values to [0, 1]\n",
    "train_images, test_images = train_images/255.0, test_images/255.0\n",
    "\n",
    "# Define the ConvNet model.\n",
    "mod = models.Sequential()\n",
    "\n",
    "mod.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)))\n",
    "mod.add(layers.MaxPooling2D((2, 2)))\n",
    "mod.add(layers.Conv2D(64, (3, 3), activation ='relu', padding='same'))\n",
    "mod.add(layers.MaxPooling2D((2, 2)))\n",
    "mod.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "\n",
    "mod.add(layers.Flatten())\n",
    "mod.add(layers.Dense (128, activation='relu'))\n",
    "\n",
    "mod.add(layers. Dense(10, activation='softmax'))\n",
    "\n",
    "# print the mod summary\n",
    "mod.summary()\n",
    "\n",
    "# Compile the mod with sparse_categorical_crossentropy\n",
    "mod.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the mod\n",
    "mod.fit(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels))\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
    "\n",
    "print(f\"Test Accuracy: {test_accuracy * 100}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
