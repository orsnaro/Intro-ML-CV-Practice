{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # **Name:** _Omar Rashad Salem_\n",
    "> # **Course:** _CV - prof.Heba_\n",
    "> # **Assignemnt No.:** _4_\n",
    "\n",
    "> ## QUESTIONS\n",
    "\n",
    "##### _1)_ **What is a Convolutional Neural Network (CNN) and what makes it suitable for image-related tasks?**\n",
    "\n",
    "**ans:** \n",
    "- CNN  is type of neural networks that is used for processing  a higher dimensional type of data or cluster of data like images e.g.(rgb / gray scale) it posseses the ability to learn  patterns and hierarchical\n",
    " representations\n",
    "----\n",
    "\n",
    "##### _2)_ **Explain the concept of local connectivity in CNNs.**\n",
    "\n",
    "**ans:**  output of neuron in a X layer connects only to a small local region in the next layer that mostly share some similar context.  this effectively reduces `CNN` complexity and optimizes it!\n",
    "\n",
    "----\n",
    "##### _3)_ **What are the key parameters of a Convolutional Layer?**\n",
    "\n",
    "**ans:** \n",
    "- No. of filters `K`\n",
    "- Stride `S`\n",
    "- Filter size `F`\n",
    "- Zero padding `P`\n",
    "\n",
    "\n",
    "----\n",
    "##### _4)_ **Why is zero-padding used in Convolutional Layers, and what impact does it have on the spatial arrangement?**\n",
    "\n",
    "**ans:**\n",
    "- preserves the input dimensions / makes it managable\n",
    "- marks the edges of an images which could come very handy in image processing and computer vision\n",
    "\n",
    "----\n",
    "##### _5)_ **What is the purpose of pooling layer in ConvNet?**\n",
    "\n",
    "\n",
    "**ans:** \n",
    "- reduces the dimensions and parameters which helps boosting CNN over all performance and computing time\n",
    "- produces no extra parameters \n",
    "\n",
    "\n",
    "----\n",
    "##### _6)_ **SOLVE**\n",
    "given:\n",
    "\n",
    "\t\t- filter size = 2x2\n",
    " \t\t- stride = 2\n",
    "\t\t- i/p size = 28x28x64\n",
    "\t\t- it's a pooling layer\n",
    "\n",
    "* Find o/p Volume?\n",
    "\n",
    "**ans:** \n",
    "$$\n",
    "\tW = (w - f)/s + 1\n",
    "\t\\\\\n",
    "\tW = (16 - 2) / 2 + 1\n",
    "\t\\\\\n",
    "\t\\therefore W = 14\n",
    "\t\\\\\n",
    "\to/p-Volume = 14 * 14 * 64\n",
    "\t\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "----\n",
    "##### _7)_ **SOLVE**\n",
    "\n",
    "given:\n",
    "\t\t- (assume padding = 1)\n",
    "\t\t- filter size = 3x3\n",
    "\t\t- filters No. = 32\n",
    " \t\t- stride = 1\n",
    "\t\t- i/p size = 32x32x3\n",
    "\t\t- it's a Convolution layer\n",
    "\n",
    "* Find o/p Volume?\n",
    "\n",
    "**ans:** \n",
    "$$\n",
    "\tW = (w - f + 2p)/s + 1\n",
    "\t\\\\\n",
    "\tW = (32 - 3 + 2*1) / 1 + 1\n",
    "\t\\\\\n",
    "\t\\therefore W = 32\n",
    "\t\\\\\n",
    "\to/p-Volume = 30 * 30 * 32\n",
    "\t\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "----\n",
    "##### _8)_ **SOLVE**\n",
    "\n",
    "given:\n",
    "\n",
    "\t\t- filter size = 3x3\n",
    "\t\t- filters No. = 8\n",
    " \t\t\n",
    "* Find No. of parameters including biases?\n",
    "\n",
    "**ans:** \n",
    "$$\n",
    "\tNo.parameters = filter'size * depth * biases\n",
    "\t\\\\\n",
    "\t= 3 * 3 * 3 + 1 \n",
    "\t\\\\\n",
    "\to/p-Volume = 28 \n",
    "\t\\\\\n",
    "\t\\therefore No.parameters = 28*8 = 224 (216weight  + 8biases)\n",
    "$$\n",
    "\n",
    "\n",
    "----\n",
    "##### _9)_ **SOLVE**\n",
    "\n",
    "given:\n",
    "\n",
    "\t\t- i/p volume = 256*256*3\n",
    "\t\t- layer neurons no. = 100\n",
    " \t\t\n",
    "* Find No. weights and biases needed?\n",
    "\n",
    "**ans:** \n",
    "$$\n",
    "\tweights = 256*256*3*100 \n",
    "\t\\\\\n",
    "\tweights = 19660800\n",
    "\t\\\\\n",
    "\tbiases = 1*100 = 100\n",
    "$$\n",
    "\n",
    "\n",
    "----\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Programming Assignment _(challenge task!)_: \n",
    "> #### Image Classification using Convolutional Neural Networks (ConvNet)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # Code for accuracy FOCUSED CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install imgaug\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from imgaug import augmenters as iaa\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout, BatchNormalization, GlobalMaxPooling2D\n",
    "\n",
    "\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "(xtr, ytr), (xtst, ytst) = cifar10.load_data()\n",
    "xeval, xtr, yeval, ytr = train_test_split(  xtr, ytr, test_size= 1000, random_state= 42 )\n",
    "  \n",
    "\n",
    "# augment 25% of data and append it to train set(reform some of image to widen the range of cases that model will see)\n",
    "num_subset = 0.25 * ytr.shape[0]\n",
    "\n",
    "rand_subset_indices = np.random.choice(ytr.shape[0], int(num_subset), replace=False)\n",
    "image_subset = xtr[rand_subset_indices]\n",
    "lables_subset = ytr[rand_subset_indices]\n",
    "\n",
    "\n",
    "seq = iaa.Sequential([\n",
    "   iaa.Fliplr(0.5), #horizental\n",
    "   iaa.Crop(percent=(0, 0.1)),\n",
    "   iaa.Sometimes(\n",
    "      0.5,\n",
    "      iaa.GaussianBlur(sigma=(0, 0.5))\n",
    "   ),\n",
    "   iaa.LinearContrast((0.75, 1.5)),\n",
    "   iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5),\n",
    "   iaa.Multiply((0.8, 1.2), per_channel=0.2),\n",
    "   iaa.Affine(\n",
    "      scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},\n",
    "      translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n",
    "      rotate=(-10, 10),\n",
    "      shear=(-8, 8)\n",
    "   )], random_order= True)\n",
    "\n",
    "augmented_subset = seq(images= image_subset)\n",
    "\n",
    "#get the old images with new augmanted images (50k + 12.5k images)\n",
    "xtr = np.concatenate((xtr, augmented_subset), axis= 0)\n",
    "ytr = np.concatenate((ytr, lables_subset), axis= 0)\n",
    "\n",
    "\n",
    "# Build Accuracy focused CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, (3,3), activation= 'relu', padding= 'same', input_shape= (32, 32, 3)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, (3,3), activation= 'relu', padding='same'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, (3,3), activation= 'relu', padding='same'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, (5,5), activation= 'relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(GlobalMaxPooling2D()) #only focus on most important features (not mainly used to reduce dimensions like maxpooling2d )\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation= 'relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(10, activation= 'softmax'))\n",
    "\n",
    "print (f\"Model info: \\n {model.summary()}\")\n",
    "\n",
    "#run model and get the results\n",
    "model.compile(optimizer= 'adam', loss= 'sparse_categorical_crossentropy', metrics= ['accuracy'])\n",
    "model.fit(xtr, ytr, epochs= 100, validation_data=(xeval, yeval))\n",
    "tst_loss, tst_accuracy = model.evaluate(xtst, ytst)\n",
    "\n",
    "#print result and save model weights\n",
    "print(f\"Model Performance Result(loss,accuracy): \\n {tst_loss,tst_accuracy}\")\n",
    "model.save(r\"./assig5_model_data/assig5_model.h5\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
